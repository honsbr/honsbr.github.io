
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title></title>
  <link href="style.css" rel="stylesheet" />
  <style>
    .div1 {
      width: 50%
    }
    
    p {
      font-family:sans-serif; font-size:12px;
    }
  </style>
</head>
<body>

 <h1> hello </h1>
<p>paragraph 1</p>

  <div class="div1">
  <p>Key Components of NLP
Breaking down the complexities of human language requires NLP to focus on several key areas:
   <p>Natural Language Understanding (NLU): Parsing language to grasp the intent behind words, enabling AI to interpret requests and questions accurately.  </p>
   <p>Natural Language Generation (NLG): Generating coherent, contextually appropriate responses that feel conversational and humanlike.  </p>
   <p>Sentiment Analysis: Detecting emotions or opinions expressed in text, often used to analyze trends on social media or customer feedback.  </p>
   <p>Context Understanding: Interpreting language in the broader context of a conversation or text to ensure accurate comprehension.</p>
  
<p>Key Types of Neural Networks</p>
    <p>
    Deep learning encompasses several neural network architectures, each suited for specific tasks:
    <p>Feedforward Neural Networks (FNNs): The simplest architecture, where information flows in one direction—from input to output. These are commonly used for tasks like classifying emails as spam or not spam.</p>
    <p>Convolutional Neural Networks (CNNs): Designed for image-related tasks, CNNs excel at recognizing patterns like edges, shapes, and textures in pixels. They’re widely used in facial recognition, medical imaging, and object detection.</p>
    <p>Recurrent Neural Networks (RNNs): Built for sequential data, RNNs retain memory of past inputs, making them ideal for tasks like language modeling, time-series prediction, or stock market forecasting.</p>
    <p>Generative Adversarial Networks (GANs): Consist of two networks—a generator that creates data and a discriminator that evaluates it. GANs are responsible for realistic CGI in entertainment and art that mimics styles of famous painters.</p>
    <p>Autoencoders: These networks compress data into a smaller representation and then reconstruct it. They’re useful for tasks like denoising images or reducing file sizes while maintaining quality.</p>
    <p>Transformers: Transforming the way sequential data is processed, transformers analyze entire sequences simultaneously instead of step by step. They power advanced applications in natural language processing, like real-time translation and sophisticated chatbots.</p>
    </p>
    </div>
</body>
</html>
  
